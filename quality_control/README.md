# Quality Control

This folder contains all automated testing, debugging, and validation for the OIT platform. Run these tests after any backend or QA content changes to catch regressions.

## Folder Structure

```
quality_control/
  qa_tests/          # QA system tests (answer banks, suggestions, engine behavior)
  unit_tests/        # Backend unit tests (routes, imports, registry contracts)
  debug/             # Debug artifacts, fix logs, and status tracking
    fixes/           # Documented fixes for specific bugs
    raw/             # Raw audit/check output (JSON)
    status.md        # Current open findings and recently fixed items
```

## How to Run

Run both suites from the project root:

```bash
python -m pytest quality_control/unit_tests/ -v --tb=short
python -m pytest quality_control/qa_tests/ -v --tb=short
```

Or run everything at once:

```bash
python -m pytest quality_control/ -v --tb=short
```

## What Each Suite Covers

### `unit_tests/` (6 files, ~81 tests)

| File | Scope |
|------|-------|
| `test_01_inventory_and_imports` | Source file inventory, compile checks, import checks |
| `test_02_app_routes_and_api_contracts` | Route status codes, API request/response shapes, cache headers |
| `test_03_modules_registry_contracts` | Module registry keys, section IDs, video paths, author shape |
| `test_04_qa_loader_contracts` | Global/module bank integrity, answer references, followup chains |
| `test_05_qa_engine_behavior` | Normalization, keyword scoring, threshold, autocomplete, module scoping |
| `test_06_qa_topic_files_schema` | Topic file exports, answer/suggestion/QA shapes, keyword casing |

### `qa_tests/` (10 files, ~121 tests)

| File | Scope |
|------|-------|
| `test_01_structure` | Answer IDs, HTML safety, QA entry shape, video/next-question structure |
| `test_02_duplicates` | Duplicate answer IDs, keyword overlap, scoring collisions, suggestion dupes |
| `test_03_answer_quality` | Placeholder detection, substance checks, keyword-to-answer relevance |
| `test_04_suggestions` | Suggestion resolution, next-question diversity, module-scoped suggestions |
| `test_05_engine` | Normalization, scoring weights, threshold behavior, autocomplete limits |
| `test_06_module_banks` | Module bank isolation, answer prefix consistency, global bank containment |
| `test_07_deep_analysis` | Fuzzy duplicates, cosine similarity, n-gram overlap, readability, vocabulary richness |
| `test_08_api_payload_guardrails` | Malformed payloads, null messages, module-scoped API behavior |
| `test_09_engine_scope_regression` | Determinism, cross-module leakage, followup priority, nonsense batch queries |
| `test_10_topic_bank_reachability` | Every answer reachable by at least one entry, sample query spot-checks |

## When to Run

- After editing any `backend/qa/topics/*.py` file (answer banks, QA entries, suggestions)
- After editing `backend/qa/engine.py` or `backend/qa/loader.py`
- After editing `app.py` routes or API endpoints
- After adding/modifying module registries (`backend/modules/*/registry.py`)
- Before marking any backend task as complete

## Debug Folder (`debug/`)

The debug folder is the investigation log for the project. It tracks what was found, what was fixed, and what's still open. Consult it before debugging an issue — the answer may already be documented.

### `debug/status.md`
The live tracker. Lists current open findings, recently fixed items, and confirmed-not-bugs. Check this first to see if an issue is already known or resolved.

### `debug/fixes/`
Detailed write-ups for non-obvious bugs that required investigation. Each file documents the problem, root cause, fix, and affected files. Current fixes:

- **`video-phantom-pause-fix.md`** — Chrome fires a browser-initiated `pause` event ~20-50ms after `play()`. Fix: auto-retry `play()` once on non-user-initiated pauses. Applies to module viewer (custom overlay player) and chat video cards (native controls).

### `debug/raw/`
Machine-readable audit output (JSON). Generated by automated scans. Files include:
- `css-check.json` — CSS structure audit
- `line-stats.json` — File line counts vs 400-line policy
- `module-check.json` — Module registry validation
- `prevent-default-hits.json` — Event handler audit
- `qa-check.json` — QA bank integrity check
- `runtime.json` — Runtime endpoint probe results
- `template-checks.json` — Template structure audit

### `debug/audit-report.md`
Summary of the automated scan across all 178 project files. Lists findings by severity (high/medium/low) and includes runtime endpoint probe results.

### `debug/post-unit-debug-report.md`
Detailed report from the initial debug session. Documents the execution order, unit test outcomes, and each finding with evidence and suggested fixes.

### `debug/manual-observations.md`
Notes from manual inspection — route contract validation, unit-test alignment notes, API spot-checks.

### `debug/unit-test-run.log`
Raw pytest output from the initial test run.

## Key Reference

- `qa_tests/LLM_QA_GUARDRAILS.md` defines what qualifies as valid QA content (scoring model, threshold rules, keyword format, answer structure). Read this before writing or modifying any QA topic files.
- `debug/status.md` is the first place to check when something breaks.
- `debug/fixes/` has documented solutions for hard-to-diagnose bugs.

## Expectations

All tests must pass. If a test fails, fix the underlying issue before proceeding. Do not skip or delete tests to make a suite pass.
